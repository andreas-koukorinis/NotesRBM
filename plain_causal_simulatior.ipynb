{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain Causal Simulator\n",
    "\n",
    "This notebook fulfills the following:\n",
    "\n",
    "* a simple method for fitting a bog-standard (binary) treatment model with pre-treatment covariates. One of its uses to generate a gold standard model (by fitting it to real data) where parameters are not unrealistic.\n",
    "* a method for simulating for those models\n",
    "* a way of computing the corresponding CATEs from a fitted model\n",
    "* a way of doing column selection for introducing unmeasured confounding by dropping a subset of columns out of simulated data, so that the corresponding model should feel the impact of unmeasured confounding\n",
    "* a purely-random generator of causal models by sampling parameters.\n",
    "* illustrative examples\n",
    "\n",
    "Not done yet: `learn_backdoor_model` is appropriate for creating a simulated ground truth, but for comparisons of different methods I'd use a more specialised CATE fitting method since `learn_backdoor_model` is not targeted to that task specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from multipledispatch import dispatch\n",
    "from scipy.stats import invwishart, spearmanr\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### General Utilities\n",
    "\n",
    "General utilities not exclusive for the main goals of causal model generation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Utilities in general\n",
    "\n",
    "# Converts columns in a DataFrame to categorical where the number of unique values\n",
    "# is less than or equal to `cat_threshold`.\n",
    "\n",
    "def dataframe_categorize(df, cat_threshold):\n",
    "  for column in df.columns:\n",
    "    if df[column].nunique() <= cat_threshold:\n",
    "      df[column] = df[column].astype(int).astype('category')\n",
    "\n",
    "# The following was generated by Copilot\n",
    "def cov_to_corr(cov_matrix):\n",
    "  \"\"\"\n",
    "  Converts a covariance matrix to a correlation matrix.\n",
    "\n",
    "  Parameters:\n",
    "      cov_matrix (numpy.ndarray): Covariance matrix.\n",
    "\n",
    "  Returns:\n",
    "      numpy.ndarray: Correlation matrix.\n",
    "  \"\"\"\n",
    "  std_dev = np.sqrt(np.diag(cov_matrix))\n",
    "  outer_std_dev = np.outer(std_dev, std_dev)\n",
    "  corr_matrix = cov_matrix / outer_std_dev\n",
    "  corr_matrix[np.diag_indices_from(corr_matrix)] = 1    \n",
    "  return corr_matrix\n",
    "\n",
    "# Logistic function\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Learn a XGBoost (binary) classifier or regression function.\n",
    "# \n",
    "\n",
    "def learn_xgb(input_dat, output_dat):\n",
    "\n",
    "  param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "  }\n",
    "\n",
    "  if isinstance(output_dat.dtype, pd.CategoricalDtype):\n",
    "    bst = xgb.XGBClassifier(objective='binary:logistic', enable_categorical=True)\n",
    "  else:\n",
    "    bst = xgb.XGBRegressor(objective='reg:squarederror', enable_categorical=True)\n",
    "\n",
    "  grid_search = GridSearchCV(estimator=bst, param_grid=param_grid, cv=3, scoring='accuracy', verbose=0)\n",
    "  grid_search.fit(input_dat, output_dat)\n",
    "  bst = grid_search.best_estimator_\n",
    "\n",
    "  return bst\n",
    "\n",
    "# Predict expected value of output of a XGBoost model `bst` based on\n",
    "# input `x_val` and whether output is categorical (`y_dtype`). Only binary\n",
    "# and continuous outcomes are allowed.\n",
    "\n",
    "def predict_xgb(bst, x_eval, y_dtype):\n",
    "  if isinstance(y_dtype, pd.CategoricalDtype):\n",
    "    return bst.predict_proba(x_eval)[:, 1]\n",
    "  return bst.predict(x_eval)\n",
    "\n",
    "# Print a confusion matrix\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, labels=None):\n",
    "  cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "  cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "  print('Confusion Matrix:')\n",
    "  print(cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Parameter Learning, Simulation and Ground Truth\n",
    "\n",
    "The following piece of code fits data to a classic causal model that is fully defined by a triplet: a (binary) treatment variable $A$, some (binary or continuous) outcome $Y$, given pre-treatment covariates $X$. Conditional ignorability is assumed.\n",
    "\n",
    "There is also code for simulating from a fitted model, and a method to generate CATEs from a given model. The latter means that if a model is the ground truth one, the corresponding CATEs are ground truth. \n",
    "\n",
    "Given a model, we also have a method (`confounder_column_keeper`) to select a subset of columns to keep, while hiding others, in order to generate data from a model which violated conditional ignorability.\n",
    "\n",
    "We use `pandas.DataFrame` as our main data structure to facilitate the use of categorical data in `xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class BackdoorModel:\n",
    "#\n",
    "# This stores structural information for models composed on synthetic models, which are based on (correlated) standard Gaussians\n",
    "# as covariates, with treatment and outcome being binary variables generated by a logistic model.\n",
    "\n",
    "@dataclass\n",
    "class BackdoorModel:\n",
    "  x_idx: str                   # Column names of covariates\n",
    "  a_idx: str                   # Column name of treatment\n",
    "  y_idx: str                   # Column name of outcome\n",
    "\n",
    "# Class XGBoostBackdoorModel:\n",
    "#\n",
    "# This stores information for models fit to data, based on XGBoost for treatment and outcome,\n",
    "# and a plain empirical distribution for the covariates. \n",
    "\n",
    "@dataclass\n",
    "class XGBoostBackdoorModel(BackdoorModel):\n",
    "  bst_propensity: xgb.XGBModel # Propensity score model\n",
    "  bst_outcome: xgb.XGBModel    # Propensity score model\n",
    "  std_outcome: float           # Standard deviation of outcome regression, if applicable\n",
    "  empirical_df: pd.DataFrame   # Empirical distribution for generating covariates     \n",
    "\n",
    "# Parameter learning of basic causal model with triplet (treatment, outcome, pre_treatment covariates).\n",
    "# \n",
    "# This method adopts no model for covariates (we will use the empirical distribution). It assumes\n",
    "# a binary treatment, and either a binary or continuous outcome. It uses XGBoost for conditional \n",
    "# means and, in case out a continuous outcome, a homescedastic Gaussian error model.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `train`, a DataFrame wit the data \n",
    "# - `x_idx`, names covariate columns\n",
    "# - `a_idx`, name of treatment column\n",
    "# - `y_idx`, name of outcome column\n",
    "#\n",
    "# This returns the model for propensities, the model for the outcome, and if outcome\n",
    "# is continuous, the standard deviation of the error term, all wrapped up in\n",
    "# a `XGBoostBackdoorModel` object.\n",
    "#\n",
    "# Call this method if you want to fit a generative model. If all you wish is a CATE\n",
    "# estimator, use something else like estimate_cate_tlearner.\n",
    "\n",
    "def learn_backdoor_model(train, x_idx, a_idx, y_idx):\n",
    "  \n",
    "  x_train, a_train, y_train = train[x_idx], train[a_idx], train[y_idx]\n",
    "  ax_train = pd.concat([a_train, x_train], axis=1)\n",
    "\n",
    "  bst_propensity = learn_xgb(x_train, a_train)\n",
    "  bst_outcome = learn_xgb(ax_train, y_train)\n",
    "\n",
    "  if isinstance(y_train.dtype, pd.CategoricalDtype):\n",
    "    std_outcome = None\n",
    "  else:\n",
    "    std_outcome = np.std(bst_outcome.predict(ax_train))\n",
    "\n",
    "  return XGBoostBackdoorModel(bst_propensity=bst_propensity, bst_outcome=bst_outcome, std_outcome=std_outcome,\n",
    "                              x_idx=x_idx, a_idx=a_idx, y_idx=y_idx, empirical_df=train)\n",
    "\n",
    "# Simulation from a fitted model.\n",
    "#\n",
    "# Basic simulation out of a causal model based on a XGBoost fit. Covariates are generated\n",
    "# from a boring model-free bootstrap sample out of `model.empirical_pd`.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `n` is the number of samples\n",
    "# - `model` is a fitted model of the type `XBoostBackdoorModel`\n",
    "\n",
    "@dispatch(int, XGBoostBackdoorModel)\n",
    "def simulate_from_backdoor_model(n, model):\n",
    "  row_choices = np.random.choice(range(model.empirical_df.shape[0]), size=n)\n",
    "  df_sample = model.empirical_df.iloc[row_choices, :].reset_index(drop=True)\n",
    "  propensities = model.bst_propensity.predict_proba(df_sample[model.x_idx])[:, 1]\n",
    "  df_sample[model.a_idx] = np.random.binomial(n=1, p=propensities)\n",
    "  df_sample[model.a_idx] = df_sample[model.a_idx].astype('category') # Somehow, this is necessary\n",
    "\n",
    "  e_y = predict_xgb(model.bst_outcome, df_sample[[*[model.a_idx], *model.x_idx]], model.empirical_df[model.y_idx].dtype)\n",
    "  if model.std_outcome == None:\n",
    "    df_sample[model.y_idx] = np.random.binomial(n=1, p=e_y)\n",
    "    df_sample[model.y_idx] = df_sample[model.y_idx].astype('category') # Somehow, this is necessary\n",
    "  else:\n",
    "    df_sample[model.y_idx] = e_y + np.random.normal(loc=0, scale=model.std_outcome, size=n)\n",
    "\n",
    "  return df_sample\n",
    "\n",
    "@dispatch(int, XGBoostBackdoorModel)\n",
    "def simulate_from_controlled_backdoor_model(n, model):\n",
    "  row_choices = np.random.choice(range(model.empirical_df.shape[0]), size=n)\n",
    "  df_sample = model.empirical_df.iloc[row_choices, :].reset_index(drop=True)\n",
    "  df_sample[model.a_idx] = np.random.binomial(n=1, p=0.5 * np.ones(n))\n",
    "  df_sample[model.a_idx] = df_sample[model.a_idx].astype('category') # Somehow, this is necessary\n",
    "\n",
    "  e_y = predict_xgb(model.bst_outcome, df_sample[[*[model.a_idx], *model.x_idx]], model.empirical_df[model.y_idx].dtype)\n",
    "  if model.std_outcome == None:\n",
    "    df_sample[model.y_idx] = np.random.binomial(n=1, p=e_y)\n",
    "    df_sample[model.y_idx] = df_sample[model.y_idx].astype('category') # Somehow, this is necessary\n",
    "  else:\n",
    "    df_sample[model.y_idx] = e_y + np.random.normal(loc=0, scale=model.std_outcome, size=n)\n",
    "\n",
    "  return df_sample\n",
    "\n",
    "# Selection of observable columns.\n",
    "#\n",
    "# This decides which covariates to keep so that everything else will count as unmeasured \n",
    "# # confounding. We will use XGBoost's built-in measure of variable importance to decide \n",
    "# which variables to be throw out.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `keep_k`: how many of the covariates to keep as observable.\n",
    "# - `model`: the corresponding `XGBoostBackdoorModel` model.\n",
    "\n",
    "@dispatch(int, XGBoostBackdoorModel)\n",
    "def confounder_column_keeper(keep_k, model):\n",
    "  keep_x = np.argsort(model.bst_propensity.feature_importances_)[-keep_k:]\n",
    "  x_select = [model.x_idx[i] for i in keep_x]\n",
    "  return x_select\n",
    "\n",
    "# Compute CATE from given model.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `df_sample` is the table of covariates we evaluate at\n",
    "# - `model` is the corresponding `XGBoostBackdoorModel` fitted model.\n",
    "\n",
    "@dispatch(pd.DataFrame, XGBoostBackdoorModel)\n",
    "def get_cate(df_sample, model):\n",
    "  \n",
    "  n = df_sample.shape[0]\n",
    "  a = pd.DataFrame(np.zeros([n, 1]), columns=[model.a_idx])\n",
    "  ax_sample = pd.concat([a, df_sample[model.x_idx]], axis=1)\n",
    "  cate = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "  for i in [0, 1]:\n",
    "    e_y = predict_xgb(model.bst_outcome, ax_sample, df_sample[model.y_idx].dtype)\n",
    "    cate = cate + (2 * i - 1) * e_y\n",
    "    ax_sample[model.a_idx] = ax_sample[model.a_idx] + 1\n",
    "  \n",
    "  return cate\n",
    "\n",
    "# The following gets a Monte Carlo estimation of CATE with respect to a model\n",
    "# where only a subset of the covariates is conditioned on.\n",
    "#\n",
    "# It does it by:\n",
    "#\n",
    "# 1. Generating a large Monte Carlo sample (as given by `num_simulations`)\n",
    "#    where we first \"delete the edges\" from X to A and do uniform sampling\n",
    "#    of A.\n",
    "# 2. Fit a XGBoost model for the outcome model only on the columns\n",
    "#    `x_select` that have been previously chosen. This is the Monte Carlo\n",
    "#    bit, as the model is an approximation to the (assumed to be know)\n",
    "#    implied marginal CATE model of `model` with respect to `x_select`,\n",
    "#    for which we don't have an analytical solution.\n",
    "# 3. Apply the XGBoost model to the units in `df_sample` with respect o\n",
    "#    `x_select`\n",
    "\n",
    "def get_montecarlo_cate(data_eval, x_select, num_simulations, model, use_logistic=False):\n",
    "\n",
    "  x_eval = data_eval[x_select]\n",
    "  cate_eval = np.zeros(x_eval.shape[0])\n",
    "  monte_carlo_sample = simulate_from_controlled_backdoor_model(num_simulations, model)\n",
    "\n",
    "  for i in [0, 1]:\n",
    "    sel_train = monte_carlo_sample[model.a_idx] == i \n",
    "    x_train = monte_carlo_sample[x_select][sel_train]\n",
    "    y_train = monte_carlo_sample[model.y_idx][sel_train]\n",
    "\n",
    "    if use_logistic:\n",
    "      lgt_montecarlo = LogisticRegression()\n",
    "      lgt_montecarlo.fit(x_train, y_train)\n",
    "      e_y = lgt_montecarlo.predict_proba(x_eval)[:, 1]\n",
    "    else:\n",
    "      bst_montecarlo = learn_xgb(x_train, y_train) \n",
    "      e_y = predict_xgb(bst_montecarlo, x_eval, y_train.dtype)\n",
    "    cate_eval = cate_eval + (2 * i - 1) * e_y\n",
    "      \n",
    "  return cate_eval\n",
    "\n",
    "# Estimate in-sample cate based on data that is assumed to be conditionally ignorable\n",
    "# (RCTs/backdoor) using a T-Learner based on XGBoost and only covariate columns `x_select`.\n",
    "\n",
    "def estimate_cate_tlearner(data, x_select, model):\n",
    "  \n",
    "  x_data = data[x_select]\n",
    "  cate_hat = np.zeros(data.shape[0])\n",
    "  bst_outcome = [None, None]\n",
    "\n",
    "  for i in [0, 1]:\n",
    "    sel_train = data[model.a_idx] == i \n",
    "    x_train = data[x_select][sel_train]\n",
    "    y_train = data[model.y_idx][sel_train]\n",
    "\n",
    "    bst_outcome[i] = learn_xgb(x_train, y_train)\n",
    "    e_y = predict_xgb(bst_outcome[i], x_data, y_train.dtype)\n",
    "    cate_hat = cate_hat + (2 * i - 1) * e_y\n",
    "      \n",
    "  return cate_hat, bst_outcome\n",
    "\n",
    "# Use an outlier detection method to evaluate which points are \n",
    "# in the support of the distribution.\n",
    "# \n",
    "# In the output, '1' means in-support, '0' means out of support.\n",
    "#\n",
    "# The scores are such that the higher, the more confidence we have about\n",
    "# that point being in-distribution.\n",
    "#\n",
    "# TODO: hyperparameter optimization\n",
    "\n",
    "def learn_support_classifier(train, test):\n",
    "  clf = IsolationForest(random_state=0).fit(train)\n",
    "  predictions = clf.predict(test)\n",
    "  predictions[predictions == -1] = 0\n",
    "  score = clf.score_samples(test)\n",
    "  return predictions, score  \n",
    "\n",
    "# =================================================================================================================\n",
    "# =================================================================================================================\n",
    "# The following focuses on functions for the fully synthetic case, where the random model is based on Gaussian \n",
    "# distributions for the covariates, and conditional logistic models for the treatment and outcome.\n",
    "# =================================================================================================================\n",
    "# =================================================================================================================\n",
    "\n",
    "# Class SyntheticBackdoorModel\n",
    "#\n",
    "# This stores information for synthetic models, which are based on (correlated) standard Gaussians\n",
    "# as covariates, with treatment and outcome being binary variables generated by a logistic model.\n",
    "\n",
    "@dataclass\n",
    "class SyntheticBackdoorModel(BackdoorModel):\n",
    "  cov_x: np.array    # Covariance of covariates\n",
    "  coeff_a: np.array  # Coefficients for logistic model of treatment on covariates\n",
    "  coeff_y: np.array  # Coefficients for logistic model of outcome of treatment and covariates\n",
    "\n",
    "# Generate parameters of a SyntheticBackdoorModel.\n",
    "#\n",
    "# This is done by sampling the covariance matrix of covariates out of a inverse Wishart\n",
    "# distribution, where the scale parameter is a correlation matrix with off-diagonal\n",
    "# elements being given by `rho`. The degrees of freedom are set to a minimum viable\n",
    "# amount to make the sampling distribution of covariance matrices more diffuse.\n",
    "#\n",
    "# We then rescale these covariances to have a diagonal of 1.\n",
    "#\n",
    "# Another important input is `prob_positive`, which adds a bias for positive\n",
    "# coefficients in the model. This is to avoid expected cancellations when `num_x`\n",
    "# is large so that the total effect of covariates is not accidentally small.\n",
    "\n",
    "def simulate_synthetic_backdoor_parameters(num_x, rho, prob_positive):\n",
    "  df = num_x + 1\n",
    "  shape_mat = np.ones([num_x, num_x]) * rho\n",
    "  shape_mat[np.diag_indices_from(shape_mat)] = 1    \n",
    "  cov_x = cov_to_corr(invwishart.rvs(df=df, scale=shape_mat*df))\n",
    "\n",
    "  coeff_a = np.abs(np.random.normal(loc=0, scale=1/np.sqrt(num_x), size=num_x + 1))\n",
    "  sign = np.random.uniform(size=num_x + 1)\n",
    "  coeff_a[sign > prob_positive] = -coeff_a[sign > prob_positive]\n",
    "\n",
    "  coeff_y = np.abs(np.random.normal(loc=0, scale=1/np.sqrt(num_x + 1), size=num_x + 2))\n",
    "  sign = np.random.uniform(size=num_x + 2)\n",
    "  coeff_y[sign > prob_positive] = -coeff_y[sign > prob_positive]\n",
    " \n",
    "  a_idx = 'A'\n",
    "  x_idx = ['X' + str(i) for i in range(num_x)]\n",
    "  y_idx = 'Y'\n",
    "\n",
    "  new_model = SyntheticBackdoorModel(cov_x=cov_x, coeff_a=coeff_a, coeff_y=coeff_y,\n",
    "                                     x_idx=x_idx, a_idx=a_idx, y_idx=y_idx)\n",
    "  return new_model\n",
    "\n",
    "# Simulation from a fitted model.\n",
    "#\n",
    "# Basic simulation out of a causal model based on a Gaussian/llogistic fit.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `n` is the number of samples\n",
    "# - `model` is a fitted model of the type `SyntheticBackdoorModel`\n",
    "\n",
    "@dispatch(int, SyntheticBackdoorModel)\n",
    "def simulate_from_backdoor_model(n, model):\n",
    "  num_x = model.cov_x.shape[0]\n",
    "  x = np.random.multivariate_normal(np.zeros(num_x), model.cov_x, n)\n",
    "  a_prob = logistic(np.concatenate((np.ones([n, 1]), x), axis=1)@model.coeff_a)\n",
    "  a = np.array(np.random.uniform(0, 1, size=n) <= a_prob, dtype=int).reshape(n, 1)\n",
    "  y_prob = logistic(np.concatenate((np.ones([n, 1]), x, a), axis=1)@model.coeff_y)\n",
    "  y = np.array(np.random.uniform(0, 1, size=n) <= y_prob, dtype=int).reshape(n, 1)\n",
    "\n",
    "  dat = pd.DataFrame(np.concatenate([a, x, y], axis=1), \n",
    "                     columns=[model.a_idx] + model.x_idx + [model.y_idx])\n",
    "  dataframe_categorize(dat, 2)\n",
    "\n",
    "  return dat\n",
    "\n",
    "@dispatch(int, SyntheticBackdoorModel)\n",
    "def simulate_from_controlled_backdoor_model(n, model):\n",
    "  num_x = len(model.x_idx)\n",
    "  controlled_model = copy.deepcopy(model)\n",
    "  controlled_model.coeff_a = np.zeros(num_x + 1) # Erase \"edges\" from X to A\n",
    "  dat = simulate_from_backdoor_model(n, controlled_model) \n",
    "  return dat\n",
    "\n",
    "# Selection of observable columns.\n",
    "#\n",
    "# This decides which covariates to keep so that everything else will count as unmeasured \n",
    "# # confounding. We will the absolute value of the logistic coefficients for that.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `keep_k`: how many of the covariates to keep as observable.\n",
    "# - `model`: the corresponding `SyntheticBackdoorModel` model.\n",
    "\n",
    "@dispatch(int, SyntheticBackdoorModel)\n",
    "def confounder_column_keeper(keep_k, model):\n",
    "  keep_x = np.argsort(np.abs(model.coeff_a[1:]))[-keep_k:]\n",
    "  x_select = [model.x_idx[i] for i in keep_x]\n",
    "  return x_select\n",
    "\n",
    "# Compute CATE from given model.\n",
    "#\n",
    "# Inputs:\n",
    "#\n",
    "# - `df_sample` is the table of covariates we evaluate at\n",
    "# - `model` is the corresponding `SyntheticBackdoorModel` fitted model.\n",
    "\n",
    "@dispatch(pd.DataFrame, SyntheticBackdoorModel)\n",
    "def get_cate(df_sample, model):\n",
    "  \n",
    "  n = df_sample.shape[0]\n",
    "  x = df_sample[model.x_idx]\n",
    "  a = np.zeros([n, 1])\n",
    "  cate = np.zeros(n)\n",
    "\n",
    "  for i in [0, 1]:      \n",
    "    e_y = logistic(np.concatenate((np.ones([n, 1]), x, a), axis=1)@model.coeff_y)\n",
    "    cate = cate + (2 * i - 1) * e_y\n",
    "    a = a + 1\n",
    "  \n",
    "  return cate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example of Application (Based on Real Data)\n",
    "\n",
    "The following fits real data to some postulated causal structure, and then runs a pipeline of steps to compare how badly unmeasured confounding has affected a simple model fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ground truth model...\n",
      "Fitting Monte Carlo approximation of ground truth CATE with unmeasured confounding...\n",
      "Fitting causal effect estimators...\n",
      "\n",
      "RESULTS FOR SEMI-SYNTHETIC DATA EXPERIMENT\n",
      "------------------------------------------\n",
      "Mean absolute CATE error for correct case: 0.024482564080845332\n",
      "Mean absolute CATE error for biased case: 0.05995307259559631\n",
      "ATE error for correct case: -0.00827891700429085\n",
      "ATE error for biased case: -0.05995307259559632\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE OF APPLICATION\n",
    "#\n",
    "# This data is the diabetes data from the UCI repository, available at \n",
    "# https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset\n",
    "#\n",
    "# The \"application\" below is totally bogus. I'm using blood pressure as the cause (\"A\"), and heart disease as\n",
    "# the outcome (\"Y\"). Everything else are \"pre-treatment\" covariates X, and that there is no unmeasured \n",
    "# confounding left. Of course there is no reason to believe that either of those assestions are true. \n",
    "# The point is just to generate synthetic data from parameters which are not arbitrary.\n",
    "#\n",
    "# This made-up example has very weak effects.\n",
    "\n",
    "cat_threshold = 10 # How many unique values in a column before we decide for it to be continuous\n",
    "n = 50000 # Large sample size to more easily understand the effect of a wrong model\n",
    "keep_k = 1 # This is a very sparse model, removing all but one of the covariates for illustration purposes\n",
    "num_simulations = 100000 # To fit a model for Monte Carlo calculation of true CATE\n",
    "\n",
    "df_main = pd.read_csv('/Users/ricardosilva/Downloads/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "dataframe_categorize(df_main, cat_threshold)\n",
    "a_idx, y_idx = 'HighBP', 'HeartDiseaseorAttack'\n",
    "x_idx = list(set(df_main.columns) - set([a_idx, y_idx]))\n",
    "\n",
    "# Train simulated model and generate synthetic data from fitted model, along with ground truth CATE\n",
    "print('Fitting ground truth model...')\n",
    "bst_model = learn_backdoor_model(df_main, x_idx, a_idx, y_idx)\n",
    "df_sample = simulate_from_backdoor_model(n, bst_model)\n",
    "true_cate = get_cate(df_sample, bst_model)\n",
    "print('Fitting Monte Carlo approximation of ground truth CATE with unmeasured confounding...')\n",
    "x_select = confounder_column_keeper(keep_k, bst_model)\n",
    "true_cate_xselect = get_montecarlo_cate(df_sample, x_select, num_simulations, bst_model)\n",
    "\n",
    "# Fit model with all covariates, and a subset of the covariates\n",
    "print('Fitting causal effect estimators...')\n",
    "cate_hat_full, _ = estimate_cate_tlearner(df_sample, bst_model.x_idx, bst_model)\n",
    "cate_hat_xselect, _ = estimate_cate_tlearner(df_sample, x_select, bst_model)\n",
    "\n",
    "print()\n",
    "\n",
    "# Please notice that the CATE cases are not directly comparable, as the CATE changes between problems\n",
    "print('RESULTS FOR SEMI-SYNTHETIC DATA EXPERIMENT')\n",
    "print('------------------------------------------')\n",
    "print('Mean absolute CATE error for correct case:', np.mean(abs(true_cate - cate_hat_full)))\n",
    "print('Mean absolute CATE error for biased case:', np.mean(abs(true_cate_xselect - cate_hat_xselect)))\n",
    "print('ATE error for correct case:', np.mean(true_cate) - np.mean(cate_hat_full))\n",
    "print('ATE error for biased case:', np.mean(true_cate_xselect) - np.mean(cate_hat_xselect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example of Application (Purely Synthetic Data)\n",
    "\n",
    "The following sample parameters of a postulated causal structure, and then runs a pipeline of steps to compare how badly unmeasured confounding has affected a simple model fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Monte Carlo approximation of ground truth CATE with unmeasured confounding...\n",
      "Fitting causal effect estimators...\n",
      "\n",
      "RESULTS FOR PURELY SYNTHETIC DATA EXPERIMENT\n",
      "--------------------------------------------\n",
      "Mean absolute CATE error for correct case: 0.058161083194382374\n",
      "Mean absolute CATE error for biased case: 0.09034168918177485\n",
      "ATE error for correct case: -0.020486986545175313\n",
      "ATE error for biased case: -0.032672322159260504\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE OF APPLICATION\n",
    "#\n",
    "# The model is purely synthetic. Check class `SyntheticBackdoorModel` for more information about\n",
    "# its structure.\n",
    "\n",
    "num_x = 20          # Number of covariates\n",
    "rho = 0.2           # Hyperparameter controlling how (positively) correlated covariates are expected to be\n",
    "prob_positive = 0.7 # Bias for positive coefficients\n",
    "n = 50000           # Large sample size to more easily understand the effect of a wrong model\n",
    "keep_k = 1          # This is a very sparse model, removing all but one of the covariates for illustration purposes\n",
    "\n",
    "# Randomly generate simulated model and then generate synthetic data from fitted model, along with ground truth CATE.\n",
    "synth_model = simulate_synthetic_backdoor_parameters(num_x, rho, prob_positive)\n",
    "df_sample_synth = simulate_from_backdoor_model(n, synth_model)\n",
    "true_cate_synth = get_cate(df_sample_synth, synth_model)\n",
    "print('Fitting Monte Carlo approximation of ground truth CATE with unmeasured confounding...')\n",
    "x_select_synth = confounder_column_keeper(keep_k, synth_model)\n",
    "true_cate_xselect = get_montecarlo_cate(df_sample_synth, x_select_synth, num_simulations, synth_model)\n",
    "\n",
    "# Fit model with all covariates, and a subset of the covariates. Notice that we\n",
    "# still use XGBoost to fit models here.\n",
    "print('Fitting causal effect estimators...')\n",
    "cate_hat_full_synth, _ = estimate_cate_tlearner(df_sample_synth, synth_model.x_idx, synth_model)\n",
    "cate_hat_xselect_synth, _ = estimate_cate_tlearner(df_sample_synth, x_select_synth, synth_model)\n",
    "\n",
    "print()\n",
    "\n",
    "# Please notice that the CATE cases are not directly comparable, as the CATE changes between problems\n",
    "print('RESULTS FOR PURELY SYNTHETIC DATA EXPERIMENT')\n",
    "print('--------------------------------------------')\n",
    "print('Mean absolute CATE error for correct case:', np.mean(abs(true_cate - cate_hat_full_synth)))\n",
    "print('Mean absolute CATE error for biased case:', np.mean(abs(true_cate_xselect - cate_hat_xselect_synth)))\n",
    "print('ATE error for correct case:', np.mean(true_cate) - np.mean(cate_hat_full_synth))\n",
    "print('ATE error for biased case:', np.mean(true_cate_xselect) - np.mean(cate_hat_xselect_synth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Debug Code: How Good is My CATE Estimation?\n",
    "\n",
    "The following generates synthetic data, then does CATE estimation using a plain T-Learner with correct assumptions of conditional ignorability. With large sample sizes, it should do OK.\n",
    "\n",
    "Two points to be tested:\n",
    "\n",
    "* while `get_cate` can get the exact CATE, it only works if we condition on all covariates used to generate the data. In contrast, `get_montecarlo_cate` uses Monte Carlo simulation for when, even when using the true parameters, we focus at a different CATE using a subset of the covariates. This has no analytical formula, hence the simulation. This code tests this implementation.\n",
    "\n",
    "* we also compare how well our default estimation method, the T-Learner with XGBoost (to be replaced eventually) does in terms of recovering the ground truth CATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS OF SIMULATION\n",
    "#\n",
    "\n",
    "num_x = 20             # Number of covariates\n",
    "rho = 0.2              # Hyperparameter controlling how (positively) correlated covariates are expected to be\n",
    "prob_positive = 0.7    # Bias for positive coefficients\n",
    "n = 500000             # Large sample size to more easily understand the effect of possible bugs\n",
    "n_simulations = 100000 # Number of Monte Carlo simulations\n",
    "\n",
    "# GENERATE SYNTHETIC MODEL AND EXACT CATEs\n",
    "# \n",
    "\n",
    "synth_model = simulate_synthetic_backdoor_parameters(num_x, rho, prob_positive) # Model parameters\n",
    "df_sample_synth = simulate_from_backdoor_model(n, synth_model)                  # Data sampled from model to define where CATE is learned\n",
    "true_cate_synth = get_cate(df_sample_synth, synth_model)       \n",
    "\n",
    "# GET MONTECARLO CATE AND COMPARE\n",
    "#\n",
    "\n",
    "print('Getting Monte Carlo estimate of true CATE...')\n",
    "true_cate_synth_montecarlo = get_montecarlo_cate(df_sample_synth, synth_model.x_idx, n_simulations, synth_model)\n",
    "true_cate_synth_montecarlo_logistic = get_montecarlo_cate(df_sample_synth, synth_model.x_idx, n_simulations, synth_model, use_logistic=True)\n",
    "print()\n",
    "\n",
    "print('RESULTS FOR MONTE CARLO EXPERIMENT')\n",
    "print('----------------------------------')\n",
    "print('Absolute CATE error for correct model:', np.mean(abs(true_cate_synth - true_cate_synth_montecarlo)))\n",
    "print('ATE error for correct model:', np.mean(true_cate_synth) - np.mean(true_cate_synth_montecarlo))\n",
    "print('Rank correlation of exact and Monte Carlo CATEs: ', spearmanr(true_cate_synth, true_cate_synth_montecarlo)[0])\n",
    "print('Absolute CATE error for correct model (logistic):', np.mean(abs(true_cate_synth - true_cate_synth_montecarlo_logistic)))\n",
    "print('ATE error for correct model (logistic):', np.mean(true_cate_synth) - np.mean(true_cate_synth_montecarlo_logistic))\n",
    "print('Rank correlation of exact and Monte Carlo CATEs (logistic): ', spearmanr(true_cate_synth, true_cate_synth_montecarlo_logistic)[0])\n",
    "\n",
    "print()\n",
    "\n",
    "# GET T-LEARNER ESTIMATE AND COMPARE\n",
    "\n",
    "print('Learning causal effect...')\n",
    "cate_hat, _ = estimate_cate_tlearner(df_sample_synth, synth_model.x_idx, synth_model)\n",
    "print()\n",
    "\n",
    "print('RESULTS FOR ESTIMATION EXPERIMENT')\n",
    "print('---------------------------------')\n",
    "print('Absolute CATE error for estimated model vs truth:', np.mean(abs(true_cate_synth - cate_hat)))\n",
    "print('ATE error for estimated model vs truth:', np.mean(true_cate_synth) - np.mean(cate_hat))\n",
    "print('Rank correlation of true and estimated CATEs: ', spearmanr(true_cate_synth, cate_hat)[0])\n",
    "print('Absolute CATE error for estimated model vs Monte Carlo:', np.mean(abs(true_cate_synth_montecarlo - cate_hat)))\n",
    "print('ATE error for estimated model vs Monte Carlo:', np.mean(true_cate_synth_montecarlo) - np.mean(cate_hat))\n",
    "print('Rank correlation of true (Monte Carlo) and estimated CATEs: ', spearmanr(true_cate_synth_montecarlo, cate_hat)[0])\n",
    "\n",
    "plt.scatter(true_cate_synth, cate_hat)\n",
    "plt.xlabel('True CATE')\n",
    "plt.ylabel('Estimated CATE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Debug Code: Illustration of Support Detection\n",
    "\n",
    "In what follows, we will sample from a \"RCT\" according to some random rejection criterion, then a large observational sample, then\n",
    "train a classifier to see how observational samples are classified as being in the support of the RCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set assorted simulation parameters\n",
    "\n",
    "num_x = 20              # Number of covariates\n",
    "rho = 0.2               # Hyperparameter controlling how (positively) correlated covariates are expected to be\n",
    "prob_positive = 0.7     # Bias for positive coefficients\n",
    "keep_k = 20             # This indicates how many of the covariates to keep, while treating all others as hidden\n",
    "max_n_rct = 1000        # Maximum allowed RCT sample\n",
    "n_obs = 50000           # Observational sample size\n",
    "n_simulations = 100000  # Number of simulations for a Monte Carlo fitting of the CATE to a subset of covariates\n",
    "\n",
    "# Generate true causal model, plus an observational sample, and compute their corresponding true CATEs.\n",
    "# Only covariate columns in x_select are preserved, the rest are hidden (still accessible within full_obs_sample)\n",
    "\n",
    "ground_truth_model = simulate_synthetic_backdoor_parameters(num_x, rho, prob_positive)\n",
    "full_obs_sample = simulate_from_backdoor_model(n_obs, ground_truth_model)\n",
    "x_select = confounder_column_keeper(keep_k, ground_truth_model)\n",
    "obs_sample = full_obs_sample[[ground_truth_model.a_idx] + x_select + [ground_truth_model.y_idx]]\n",
    "obs_true_cates = get_montecarlo_cate(obs_sample, x_select, n_simulations, ground_truth_model)\n",
    "obs_cate_hat, _ = estimate_cate_tlearner(obs_sample, x_select, ground_truth_model)\n",
    "\n",
    "# What follows works like this: we first sample an unrestricted RCT dataset (of size n_obs).\n",
    "# We then read a matrix of restrictions which are given by matrix r_A and vector r_b where\n",
    "# we only keep those rows such that r_A * x <= r_b. \n",
    "\n",
    "pre_rct_sample = simulate_from_controlled_backdoor_model(n_obs, ground_truth_model)\n",
    "\n",
    "num_restrictions = 2\n",
    "r_A, r_b = np.zeros([num_x + 2, num_restrictions]), np.zeros(num_restrictions)\n",
    "r_A[np.where(full_obs_sample.columns == 'X1')[0][0], 0], r_b[0] = -1, -1 # X1 >= 1\n",
    "r_A[np.where(full_obs_sample.columns == 'X2')[0][0], 1], r_b[1] = 1, 0   # X2 <= 0\n",
    "drop_units = np.where((pre_rct_sample@r_A > r_b).sum(axis=1) > 0)[0]\n",
    "\n",
    "rct_sample = pre_rct_sample.drop(drop_units).reset_index(drop=True)\n",
    "if rct_sample.shape[0] > max_n_rct:\n",
    "  rct_sample = rct_sample.drop(range(max_n_rct, rct_sample.shape[0]))\n",
    "\n",
    "rct_cate_hat, _ = estimate_cate_tlearner(rct_sample, x_select, ground_truth_model)\n",
    "\n",
    "# Demonstration of support classifier\n",
    "in_rct_hat, in_rct_score_hat = learn_support_classifier(rct_sample[x_select], obs_sample[x_select])\n",
    "in_rct_goldstandard = np.array((full_obs_sample@r_A <= r_b).prod(axis=1))\n",
    "print('Rank correlation of true and estimated supports: ', spearmanr(in_rct_score_hat, in_rct_goldstandard)[0])\n",
    "print('Classification error: ', np.mean(in_rct_hat != in_rct_goldstandard))\n",
    "print('Baseline error \"all in sample\": ', np.mean(in_rct_goldstandard))\n",
    "print_confusion_matrix(in_rct_goldstandard, in_rct_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A Learning Pipeline for Matrix-Decomposition Extrapolation with Independent Components\n",
    "\n",
    "*NOTE: THE FOLLOWING IS STILL WORK IN PROGRESS!*\n",
    "\n",
    "The below is a library of functions for experimental grounding for a set of units colleted under observational conditions, using another set of units collected under a RCT. This is done by matrix factorization in a matrix containing bias correction terms between the RCT model and the observational one. The main method labels the columns by an increasing set of covariates by which we define relative CATEs. These covariates are not raw covariates, but independent components of the original covariates, so that the ordering can be decided by a simple greedy search.\n",
    "\n",
    "The main function below is`learn_eta_indep`, which works as follows. Given\n",
    "\n",
    "* `obs_sample`, the observational sample\n",
    "* `rct_sample`, the RCT sample\n",
    "* `x_select`, a list of strings containing the column names of covariates that define our CATE of interest. This is because both the data and the model may contain variables we assume to be either irrelevant, or to be hidden for benchmarking purposes\n",
    "* `model`, a basic data structure that contains the basics of the causal assumptions - basically, the name of the treatment variablee (`model.a_idx`), the name of the outcome variable (`model.y_idx`) and the list of names of the covariate variables (`model.x_idx`)\n",
    "* `max_ica_iter`, the maximum number of steps in an independent component analysis method to be called. **This means we assume that covariates are continuous, or with some generosity, binary.**\n",
    "\n",
    "The way this function works is as follows. First, using `map_to_independent`, it obtains the ICA embedding of the selected covariates, `obs_z` and `rct_z`. These are of type `np.ndarray` i.e. NumPy matrices. We call these independent features $Z$.\n",
    "\n",
    "Following that, our call to `get_id_support_masks` will run through all $Z$ variables, one at a time, and run an outlier detection method to decide which observational samples are in the marginal support of the corresponding RCT distribution. In particular,\n",
    "\n",
    "* `in_rct` is a list where `in_rct[j][i]` indicates whether the observation `obs_z[i, j]` is in the support of a distribution with sample `rct_z[:, j]` - in this case `obs_z[i,j] == 1` if the method decides it is the case.\n",
    "* `in_rct_score[i, j]` is whatever scoring criterion used by the method inside `get_1d_support_masks` to quantify how \"likely\" `obs_z[i, j]` is under the distribution learned from `rct_z[:, j]`. It is not necessarily a probability, but the higher the more likely so it can be used to rank points and decide other thresholding criteria.\n",
    "* `score_features[j]` counts many datapoints in `obs_z[:, j]` are in the support, so it's basically `np.sum(obs_z[:, j])`\n",
    "* `sorted_support` is obtained by sorting `score_features` in a decreasing order, and getting the corresponding indices. So `sorted_support[0]` indicates the feature number (the column number of `obs_z`) with a highest `score_features`, `sorted_support[1]` is a second highest, etc.\n",
    "* `M[i, k]` is a matrix of observability i.e., it indicates whether sample `obs_z[i, :]` is such that all features `obs_z[i, sorted_support[:k]]` are classified to be in the corresponding RCT supports (as recorded in `in_rct[i, :]`)\n",
    "\n",
    "Given all that information, we then call `get_cate_and_bias` to obtain\n",
    "\n",
    "* `tau[i, k]`, CATE estimates for sample `obs_z[i, sorted_support[0:k]]`, where the estimate is given by the model learned using the RCT data\n",
    "* `omega[i, k]`, CATE estimates for sample `obs_z[i, sorted_support[0:k]]`, where the estimate is given by the model learned using the observational data and corresponding assumptions\n",
    "* `eta[i, k]`, merely the difference `tau[i, k] - omega[i, k]`\n",
    "\n",
    "TODO: *the next stage does low-rank matrix completion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_eta_indep(obs_sample: pd.DataFrame, rct_sample: pd.DataFrame, \n",
    "                    x_select: list, model: BackdoorModel, max_ica_iter=1000):\n",
    "\n",
    "  # First, get the independent projections  \n",
    "  obs_z, rct_z = map_to_independent(obs_sample, rct_sample, x_select, max_ica_iter)\n",
    "\n",
    "  # Get support information:\n",
    "  # - in_rct[j][i] indicates that sample i is in the support of the RCT distribution\n",
    "  #   of feature j\n",
    "  # - in_rct_score[j][i] is a corresponding fitness criterion (the higher, the more\n",
    "  #   likely point j is in the RCT along dimension Z[j] - but this is not necessarily a probability)\n",
    "  # - score_features[j] is the number of points in the observational sample with its marginal\n",
    "  #   over Z[j] also in the support of the RCT\n",
    "  # - sorted_support[0] indicates which of j = 1, 2, ..., num_selected has the highest\n",
    "  #   corresponding score_features, sorted_support[1] has the second highest etc.\n",
    "  # - M[i, j] is 1 if datapoint i is in the support of RCT with respect to Z[sorted_support[0]:sorted_support[j]]\n",
    "  #   which here, since we are assuming independent features, can be calculated efficiently\n",
    "  in_rct, in_rct_score, score_features, sorted_support, M = get_1d_support_masks(obs_z, rct_z)\n",
    "\n",
    "  # Now, run estimators of causal effect by RCT and causal model over th entire sequence\n",
    "  # of features, without worries about extrapolation\n",
    "  tau, omega, eta = get_cate_and_bias(obs_z, rct_z, obs_sample, rct_sample, x_select, sorted_support, model)\n",
    "\n",
    "  # TODO: matrix completion\n",
    "\n",
    "  return tau, omega, eta, obs_z, rct_z, M\n",
    "  \n",
    "def map_to_independent(obs_sample: pd.DataFrame, rct_sample: pd.DataFrame, x_select: list, max_ica_iter=1000):\n",
    "  # Learn the independent components, Z, according to the observational distribution.\n",
    "  # Apply this mapping to both the observational data and the RCT sample.\n",
    "  ica = FastICA(n_components=len(x_select), random_state=0, max_iter=max_ica_iter)\n",
    "  obs_z = ica.fit_transform(obs_sample[x_select])\n",
    "  rct_z = ica.transform(rct_sample[x_select])\n",
    "  return obs_z, rct_z\n",
    "\n",
    "def get_1d_support_masks(obs_z: np.ndarray, rct_z: np.ndarray):\n",
    "  # Search for support: classify components one entry at a time to support a greedy search later.\n",
    "  # Unlike many functions here, ndarrays are used. We are representing features learned from\n",
    "  # the covariates only.\n",
    "  #\n",
    "  # In the below, \"in_rct[i]\" denotes indicates which observations samples are\n",
    "  # in the support of the RCT distribution with respect to feature Z[i]. This is\n",
    "  # a 0/1 decision. In contrast, \"in_rct_score[i]\" indicates the corresponding\n",
    "  # measures of fit: the higher, the more \"likely\" sample i is typical of the\n",
    "  # RCT distribution.\n",
    "  # \n",
    "  # \"score_features[i]\" counts how many samples are in the support of the RCT,\n",
    "  # according to dimension Z[i].\n",
    "  n, num_select = obs_z.shape[0], obs_z.shape[1]\n",
    "  in_rct, in_rct_score = [None] * num_select, [None] * num_select\n",
    "  score_features = np.zeros(num_select, dtype=int)\n",
    "  for i in range(num_select):\n",
    "    in_rct[i], in_rct_score[i] = learn_support_classifier(rct_z[:, i:i+1], obs_z[:, i:i+1])\n",
    "    score_features[i] = sum(in_rct[i])\n",
    "\n",
    "  # We will now build the support matrix for chosen features.\n",
    "  #\n",
    "  # Here, M[i, j] indicates whether observational sample i in the RCT\n",
    "  # using the first j features according to a given permutation. For\n",
    "  # the ICA-induced Z features, this is just the order given by\n",
    "  # score_features_z.\n",
    "\n",
    "  sorted_support = np.argsort(score_features)[::-1]\n",
    "  M = np.zeros([n, num_select], dtype=int)\n",
    "  M[:, 0] = in_rct[sorted_support[0]]\n",
    "  for j in range(1, num_select):\n",
    "    next_sel = in_rct[sorted_support[j]]\n",
    "    M[:, j] = M_z[:, j - 1]\n",
    "    M[next_sel == 0, j] = 0\n",
    "\n",
    "  # Now, sort rows to put cases with highest coverage earlier on.\n",
    "  # Keep track of the original positions.\n",
    "  #row_scores = np.sum(M, axis=1)\n",
    "  #new_row_idx = np.argsort(row_scores)[::-1]\n",
    "  #M = M[new_row_idx, :]\n",
    "\n",
    "  return in_rct, in_rct_score, score_features, sorted_support, M #, new_row_idx\n",
    "\n",
    "def get_cate_and_bias(obs_z: np.ndarray, rct_z: np.ndarray, \n",
    "                      obs_sample: pd.DataFrame, rct_sample: pd.DataFrame, x_select: list,\n",
    "                      sorted_support: np.ndarray, model: BackdoorModel):\n",
    "  \n",
    "  num_select = len(x_select)\n",
    "  y_type = obs_sample[model.y_idx].dtype\n",
    "\n",
    "  # First, create corresponding DataFrames out of featurized data to facilitate calling \n",
    "  # existing functions\n",
    "\n",
    "  z_idx = ['Z' + str(i) for i in range(num_select)]\n",
    "  rct_z_df = pd.DataFrame(rct_z, columns=z_idx)\n",
    "  dataframe_categorize(rct_z_df, 10)\n",
    "  rct_z_df = pd.concat([rct_sample[model.a_idx], rct_sample[model.y_idx], rct_z_df], axis=1)\n",
    "  obs_z_df = pd.DataFrame(obs_z, columns=z_idx)\n",
    "  dataframe_categorize(rct_z_df, 10)\n",
    "  obs_z_df = pd.concat([obs_sample[model.a_idx], obs_sample[model.y_idx], obs_z_df], axis=1)\n",
    "\n",
    "  rct_z_ce, obs_z_ce = [None] * num_select, [None] * num_select\n",
    "  tau, omega = np.zeros([n, num_select]), np.zeros([n, num_select])\n",
    "  for i in range(num_select):\n",
    "    z_idx_i = [z_idx[j] for j in sorted_support[:i+1]]\n",
    "    _, rct_z_ce[i] = estimate_cate_tlearner(rct_z_df, z_idx_i, model)\n",
    "    _, obs_z_ce[i] = estimate_cate_tlearner(obs_z_df, z_idx_i, model)\n",
    "    obs_z_i = obs_z_df[z_idx_i]\n",
    "    tau[:, i] = predict_xgb(rct_z_ce[i][1], obs_z_i, y_type) - \\\n",
    "                predict_xgb(rct_z_ce[i][0], obs_z_i, y_type)\n",
    "    omega[:, i] = predict_xgb(obs_z_ce[i][1], obs_z_i, y_type) - \\\n",
    "                  predict_xgb(obs_z_ce[i][0], obs_z_i, y_type)\n",
    "    \n",
    "  eta = tau - omega\n",
    "\n",
    "  return tau, omega, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
